# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LHqKXcI0a_GUY8s22kDHTlS_pFyIOA5A
"""

import streamlit as st
import numpy as np
import faiss
from groq import Groq
from sentence_transformers import SentenceTransformer
from PyPDF2 import PdfReader
from PIL import Image
import pytesseract

# ---------------------------
# CONFIG
# ---------------------------

client = Groq(api_key=st.secrets["GROQ_API_KEY"])
model_name = "openai/gpt-oss-120b"

embedding_model = SentenceTransformer("all-MiniLM-L6-v2")

CHUNK_SIZE = 800
CHUNK_OVERLAP = 100


# ---------------------------
# CHUNKING
# ---------------------------
def chunk_text(text):
    chunks = []
    for i in range(0, len(text), CHUNK_SIZE - CHUNK_OVERLAP):
        chunks.append(text[i:i + CHUNK_SIZE])
    return chunks


def create_vectorstore(text):
    chunks = chunk_text(text)
    embeddings = embedding_model.encode(chunks)
    embeddings = np.array(embeddings).astype("float32")

    dimension = embeddings.shape[1]
    index = faiss.IndexFlatL2(dimension)
    index.add(embeddings)

    return index, chunks


def retrieve(query, index, chunks, top_k=3):
    query_embedding = embedding_model.encode([query]).astype("float32")
    distances, indices = index.search(query_embedding, top_k)
    return [chunks[i] for i in indices[0]]


def generate_answer(query, context_chunks):
    context = "\n\n".join(context_chunks)

    prompt = f"""
    Answer strictly using the context below.

    Context:
    {context}

    Question:
    {query}

    If answer not found, say:
    Answer not found in the selected source.
    """

    completion = client.chat.completions.create(
        model=model_name,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
        max_completion_tokens=1024,
    )

    return completion.choices[0].message.content


# ---------------------------
# STREAMLIT UI
# ---------------------------

st.title("ðŸš€ Multimodal Groq RAG")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "doc_index" not in st.session_state:
    st.session_state.doc_index = None
    st.session_state.doc_chunks = None

if "img_index" not in st.session_state:
    st.session_state.img_index = None
    st.session_state.img_chunks = None


# -------- FILE UPLOAD --------
uploaded_file = st.file_uploader(
    "Upload PDF or Image",
    type=["pdf", "png", "jpg", "jpeg"]
)

if uploaded_file:

    if uploaded_file.type == "application/pdf":
        text_data = ""
        reader = PdfReader(uploaded_file)
        for page in reader.pages:
            text_data += page.extract_text()

        index, chunks = create_vectorstore(text_data)
        st.session_state.doc_index = index
        st.session_state.doc_chunks = chunks

        st.success("Document indexed successfully.")

    else:
        image = Image.open(uploaded_file)
        text_data = pytesseract.image_to_string(image)

        index, chunks = create_vectorstore(text_data)
        st.session_state.img_index = index
        st.session_state.img_chunks = chunks

        st.success("Image indexed successfully.")


# -------- SOURCE SELECTOR --------
source = st.radio(
    "Answer From:",
    ["Document", "Image"]
)


query = st.chat_input("Ask your question")


# -------- MAIN LOGIC --------
if query:

    if source == "Document" and st.session_state.doc_index:

        context = retrieve(
            query,
            st.session_state.doc_index,
            st.session_state.doc_chunks
        )

    elif source == "Image" and st.session_state.img_index:

        context = retrieve(
            query,
            st.session_state.img_index,
            st.session_state.img_chunks
        )

    else:
        st.error("Please upload the selected source first.")
        st.stop()

    answer = generate_answer(query, context)

    st.session_state.chat_history.append(("user", query))
    st.session_state.chat_history.append(("assistant", answer))


# -------- DISPLAY CHAT --------
for role, message in st.session_state.chat_history:
    with st.chat_message(role):
        st.write(message)
