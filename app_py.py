# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LHqKXcI0a_GUY8s22kDHTlS_pFyIOA5A
"""import streamlit as st
import requests
from PIL import Image

# ---------------- CONFIG ---------------- #

HF_API_KEY = st.secrets["HF_API_KEY"]

MODEL_URL = "https://api-inference.huggingface.co/models/nlpconnect/vit-gpt2-image-captioning"

headers = {
    "Authorization": f"Bearer {HF_API_KEY}"
}

# ---------------- IMAGE DESCRIPTION FUNCTION ---------------- #

def describe_image(image_bytes):
    response = requests.post(
        MODEL_URL,
        headers=headers,
        data=image_bytes
    )

    if response.status_code == 503:
        return "Model is loading. Please wait 30â€“60 seconds and try again."

    if response.status_code != 200:
        return f"API Error: {response.status_code}"

    try:
        result = response.json()
        if isinstance(result, list) and "generated_text" in result[0]:
            return result[0]["generated_text"]
        else:
            return str(result)
    except:
        return "Invalid API response."


# ---------------- STREAMLIT UI ---------------- #

st.title("ðŸ–¼ Free Image Understanding Assistant")

uploaded_file = st.file_uploader(
    "Upload a Person or Any Image",
    type=["png", "jpg", "jpeg"]
)

if uploaded_file:

    image = Image.open(uploaded_file)
    st.image(image, use_column_width=True)

    with st.spinner("Analyzing image..."):
        image_bytes = uploaded_file.read()
        description = describe_image(image_bytes)

    st.success("Image Description:")
    st.write(description)
