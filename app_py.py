# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LHqKXcI0a_GUY8s22kDHTlS_pFyIOA5A
"""

import streamlit as st
import requests
from PIL import Image

# ---------------- CONFIG ---------------- #

HF_API_KEY = st.secrets["HF_API_KEY"]

MODEL_URL = "https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-large"

headers = {
    "Authorization": f"Bearer {HF_API_KEY}"
}

# ---------------- SAFE API CALL ---------------- #

def query_image(image_bytes):
    response = requests.post(
        MODEL_URL,
        headers=headers,
        data=image_bytes
    )

    # Check status first
    if response.status_code == 503:
        return {"error": "Model is loading. Please wait 30-60 seconds and try again."}

    if response.status_code != 200:
        return {"error": f"API Error: {response.status_code}", "details": response.text}

    try:
        return response.json()
    except Exception:
        return {"error": "Invalid JSON response", "details": response.text}


# ---------------- STREAMLIT UI ---------------- #

st.title("ðŸ–¼ Hugging Face Vision Assistant")

uploaded_file = st.file_uploader(
    "Upload an Image",
    type=["png", "jpg", "jpeg"]
)

if uploaded_file:

    image = Image.open(uploaded_file)
    st.image(image, caption="Uploaded Image", use_column_width=True)

    with st.spinner("Analyzing image..."):

        image_bytes = uploaded_file.read()
        result = query_image(image_bytes)

        # If error returned
        if "error" in result:
            st.error(result["error"])
            if "details" in result:
                st.write(result["details"])
        else:
            if isinstance(result, list) and "generated_text" in result[0]:
                caption = result[0]["generated_text"]
                st.success("Image Description:")
                st.write(caption)
            else:
                st.write(result)
