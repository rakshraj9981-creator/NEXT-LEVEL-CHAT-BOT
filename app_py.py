# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LHqKXcI0a_GUY8s22kDHTlS_pFyIOA5A
"""
import streamlit as st
import requests
from PIL import Image

# ---------------- CONFIG ---------------- #

HF_API_KEY = st.secrets["HF_API_KEY"]

MODEL_URL = "https://api-inference.huggingface.co/models/llava-hf/llava-1.5-7b-hf"

headers = {
    "Authorization": f"Bearer {HF_API_KEY}"
}

# ---------------- SAFE API CALL ---------------- #

def query_llava(image_bytes, question):
    payload = {
        "inputs": {
            "image": image_bytes,
            "text": question
        }
    }

    response = requests.post(
        MODEL_URL,
        headers=headers,
        json=payload
    )

    if response.status_code == 503:
        return {"error": "Model is loading. Please wait 30â€“60 seconds and try again."}

    if response.status_code != 200:
        return {"error": f"API Error: {response.status_code}", "details": response.text}

    try:
        return response.json()
    except:
        return {"error": "Invalid response", "details": response.text}


# ---------------- UI ---------------- #

st.title("ðŸ–¼ Vision Assistant (LLaVA)")

uploaded_file = st.file_uploader(
    "Upload an Image",
    type=["png", "jpg", "jpeg"]
)

question = st.text_input("Ask something about the image")

if uploaded_file:
    image = Image.open(uploaded_file)
    st.image(image, use_column_width=True)

    if question:
        with st.spinner("Analyzing image..."):
            image_bytes = uploaded_file.read()
            result = query_llava(image_bytes, question)

            if "error" in result:
                st.error(result["error"])
                if "details" in result:
                    st.write(result["details"])
            else:
                st.success("Answer:")
                st.write(result)
